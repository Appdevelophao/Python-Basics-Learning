{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 李宏毅老师homework1 [原文代码](https://colab.research.google.com/drive/131sSqmrmWXfjFZ3jWSELl8cm0Ox5ah3C)\n",
    "# 1. 数据的读取"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 导入相应的包裤pandas和numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 读取数据并且将原始数据中“NR”替换为0，将读取的数据（dataframe) 转化为(np.array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv(\"/homework1/homework1.csv\")#文件的读取，填写好你数据文件的位置\n",
    "data[data == 'NR'] = 0 #替换不是数字型的数据，将其改为0\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_data = data.to_numpy()#因为原始数据是csv,然后用了pandas里的dataframe,现在这一步是为了将dataframe转化为np.array\n",
    "raw_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 为了方便起见，我只用了2个月的数据（原来课件是包含12个月数据)，大家按自己的需求适当调整下代码即可。比如：你要12个月的数据，下文中的2将改为12即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data.shape)\n",
    "print(raw_data.shape)\n",
    "#这里打印出来是为了提醒大家我读取的数据是2个月的，720行=18*20*2=（18个features)*(每个月20天)*（总共2个月）\n",
    "#26列 = 每天24个小时+加上前面的2列（Dates,Features) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 数据预处理\n",
    "## 处理之后的training data 的数据结构长啥样，请看这个草图：[train_data](https://github.com/Appdevelophao/Python-Basics-Learning/blob/master/train_data_structure.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 说一下数据处理的基本思路和路线：具体长啥样请点击：[raw_sample_month](https://github.com/Appdevelophao/Python-Basics-Learning/blob/master/Lee_ML_homework1/Raw_smaple_month.jpeg)\n",
    "- Step1: sample \n",
    "- Step2: month_data\n",
    "- Step3: train_data (包括两个部分：一个是features， 另一个是labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Sample and Month_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_data =np.empty(shape=[18,480*2])#因为我这里只用了2个月的数据，所以预设的month_data的数据结构为： 18行, 480*2列。18为18个features，480=24小时*20天，2为2个月 \n",
    "for month in range(2):\n",
    "    sample=np.empty([18,480])#sample只起到中间转换的作用，sample其实就是一个月（第1st,2nd,...) 的数据,然后month_data就是将每个月（sample)的数据进行按列叠加\n",
    "    for day in range(20):\n",
    "        sample[:, day * 24: (day + 1) * 24] = raw_data[18 * (20 * month + day): 18 * (20 * month + day + 1),2:]#一天24个小时\n",
    "        #当你看不懂的这些抽象的数据表达时，你可以赋值带入具体的数字进去看看，比如：当month=0,day=0, raw_data[0:18,2:1]就是原始数据的前18行，第3列到最后一列（前两列是dates 和 features)\n",
    "        #sample[:,0:24]是一个18行，24列的np.array(一天的数据量)\n",
    "        #固定好月数， 每月20天，所以每月叠加20次， 又因为我用了2个月的数据，所以要叠加2*20次。每一个叠加单位（一天的数据）是一个18*24维度的数据\n",
    "    print(sample.shape)\n",
    "    \n",
    "    \n",
    "    month_data[:,480*month:480*(month+1)] = sample\n",
    "print(month_data.shape)\n",
    "\n",
    "month_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 train_data (x:Features, y:Labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=np.empty([2*471,18*9],dtype=float)#这是最终的训练集的features,因为每个月只有20天，每天24个小时，而且每个月的最后9个小时是用不上的，所以每个月的数据条为20*24-9=471个 \n",
    "y=np.empty([2*471,1],dtype=float) #（针对于每个特定的数据条（features), 对应于这个数据条的label就是该数据条往后推一个小时的PM2.5的值\n",
    "for month in range(2):\n",
    "    for day in range(20):\n",
    "        for hour in range(24):#想象一下：以18行9列的数据框从开始获取数据，然后每框取一次数据，该数据框就向后挪动一单位继续框取数据，在每个月内，共计框取471次\n",
    "            if day==19 and hour >14:#这个的意思是：每个月的第19天第14点到23点的数据是不需要的（每个月的最后9小时）\n",
    "                continue\n",
    "            x[month*471+day*24+hour,:]=month_data[:,480*month + day * 24 + hour : 480*month+day * 24 + hour + 9].reshape(1, -1)\n",
    "            #这里的reshape大家可以参考下数据具体长啥样子的图片， 其实本质上就是将诸多行拉长为一列， 从而形成一个数据条\n",
    "            y[month * 471 + day * 24 + hour, 0] = month_data[9, 480*month+day * 24 + hour + 9]   \n",
    "            \n",
    "            \n",
    "print('x\\' shape is ', x.shape)\n",
    "print('y\\' shape is ', y.shape)\n",
    "print(x)\n",
    "print(y)\n",
    "len(x[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 数据的归一化处理 Normalization "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_x = np.mean(x, axis = 0) # 沿着每行的行方向求均值\n",
    "std_x = np.std(x, axis = 0) # 沿着每行的行方向求标准差\n",
    "for i in range(len(x)): #2 * 471 行数\n",
    "    for j in range(len(x[0])): #18 * 9 列数\n",
    "        if std_x[j] != 0: #标准差不等于0\n",
    "            x[i][j] = (x[i][j] - mean_x[j]) / std_x[j]\n",
    "x.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4将训练集划分为测试集（train_set）和 验证集（validationion set ), 比例为 8:2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "x_train_set = x[: math.floor(len(x) * 0.8), :]\n",
    "y_train_set = y[: math.floor(len(y) * 0.8), :]\n",
    "x_validation = x[math.floor(len(x) * 0.8): , :]\n",
    "y_validation = y[math.floor(len(y) * 0.8): , :]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Regression 核心部分"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 设置一些linear Regression的参数初始值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dim = 18 * 9 + 1 #这其实就是Regression的参数的维数，每个样本数据有18*9个features,再加上一个常数项b,即为：w_1,w_2,..., w_162,b \n",
    "w = np.ones([dim, 1])# w即为参数集合，然后这里的意思是默认为参数的初始值全部设置为1，因次w为163行 1列\n",
    "x = np.concatenate((np.ones([2 * 471, 1]), x), axis = 1).astype(float)\n",
    "#这个就是就在原来 x 的基础上，在 x的右边加了一列，所以加完之后的 x的shape为：942行*163列\n",
    "\n",
    "\n",
    "adagrad = np.zeros([dim, 1])\n",
    "learning_rate = 100  # 学习率\n",
    "iter_time = 10000  # 迭代次数\n",
    "eps = 0.0000000001 #一个很小的数\n",
    "\n",
    "print(x.shape)\n",
    "print(w.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(iter_time):\n",
    "    loss = np.sqrt(np.sum(np.power(np.dot(x, w) - y, 2))/471/2)#计算损失函数:w_1*F_1+w_2*F_2+,...,w_162*F_162+b\n",
    "    if(t%100==0): #每100次打印一次损失函数\n",
    "        print(str(t) + \":\" + str(loss))\n",
    "    gradient = 2 * np.dot(x.transpose(), np.dot(x, w) - y) #dim*1\n",
    "    adagrad += gradient ** 2\n",
    "    w = w - learning_rate * gradient / np.sqrt(adagrad + eps)\n",
    "    np.save('weight.npy', w)\n",
    "w #w即为通过样本迭代了很多次计算出来的参数：w_1，w_2, ...,w_162,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 用validation的数据看看上面训练出来参数是不是OK\n",
    "- 其实熟悉的人都知道这样不合理，因为我们上面用了全部的训练集（包括了validation的数据）来训练模型，现在用再用validation来验证，这样的话，闭着验证都知道，验证的结果肯定比较好"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = np.load('weight.npy')\n",
    "# 使用x_validation和y_validation来计算模型的准确率，因为X已经normalize了，所以不需要再来一遍，只需在x_validation上添加新的一列作为bias的乘数即可\n",
    "x_validation = np.concatenate((np.ones([189, 1]), x_validation), axis=1).astype(float)\n",
    "ans_y = np.dot(x_validation, w)\n",
    "loss = np.sqrt(np.sum(np.power(ans_y - y_validation, 2)) / 1131)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 处理下测试集test_data的数据\n",
    "- 我只用了6个测试样本, 大家只需要按照自己的需要选取测试样本的个数，注意：每个测试样本是一个18*9的数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testdata=pd.read_csv(\"/homework1/homework1_test.csv\")#读取test_data\n",
    "test_data = testdata.iloc[:,2:] #切片，选择数字的部分\n",
    "test_data[test_data == 'NR'] = 0\n",
    "test_data = test_data.to_numpy() \n",
    "test_data\n",
    "test_x = np.empty([6, 18 * 9], dtype=float)\n",
    "for i in range(6):  # 共240个测试输入数据\n",
    "    test_x[i, :] = test_data[18 * i: 18 * (i + 1), :].reshape(1, -1)# 将每18行拉长变为一行，从而形成一个数据条"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 测试数据的归一标准化（和前面的几乎一样）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test_x)):\n",
    "    for j in range(len(test_x[0])):\n",
    "        if std_x[j] != 0:\n",
    "            test_x[i][j] = (test_x[i][j] - mean_x[j]) / std_x[j]\n",
    "test_x = np.concatenate((np.ones([6, 1]), test_x), axis=1).astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 利用模型完成预测 （预测工作到此结束）恭喜你"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 进行预测 \n",
    "w = np.load('weight.npy')\n",
    "ans_y = np.dot(test_x, w) \n",
    "print(ans_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 将预测结果保存在自动生成的名为submit.csv 的文件里"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "with open('submit.csv', mode='w', newline='') as submit_file:\n",
    "    csv_writer = csv.writer(submit_file)\n",
    "    header = ['id', 'value']\n",
    "    print(header)\n",
    "    csv_writer.writerow(header)\n",
    "    for i in range(6):\n",
    "        row = ['id_' + str(i), ans_y[i][0]]\n",
    "        csv_writer.writerow(row)\n",
    "        print(row)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
